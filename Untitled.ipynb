{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from string import punctuation\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('reviews.txt', 'r') as f:\n",
    "    reviews=f.read()\n",
    "    \n",
    "with open('labels.txt', 'r') as f:\n",
    "    labels=f.read()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews=''.join([c for c in reviews if c not in punctuation])\n",
    "split_reviews=reviews.split('\\n')\n",
    "full_text=' '.join(split_reviews)\n",
    "words=full_text.split()\n",
    "word_count=Counter(words)\n",
    "vocab=sorted(word_count, key=word_count.get, reverse=True)\n",
    "vocab2int={w:i for i, w in enumerate(vocab, 1)}\n",
    "review_ints=[]\n",
    "for review in split_reviews:\n",
    "    review_ints.append([vocab2int[word] for word in review.split()])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_=labels.split('\\n')\n",
    "labels_int=np.array([1 if label=='positive' else 0 for label in labels_])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-length reviews: 1\n",
      "Maximum review length: 2514\n"
     ]
    }
   ],
   "source": [
    "review_lens=Counter([len(x) for x in review_ints])\n",
    "print(\"Zero-length reviews: {}\".format(review_lens[0]))\n",
    "print(\"Maximum review length: {}\".format(max(review_lens)))\n",
    "#reviews of  length 200 is fed into network zero length review is padded with zeros and others are truncated to 200 \n",
    "#characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len=200\n",
    "non_zero_idx=[i for i, r in enumerate(review_ints) if len(r)!=0]\n",
    "review_ints=[review_ints[i] for i in non_zero_idx]\n",
    "labels_int=[labels_int[i] for i in non_zero_idx]\n",
    "features=np.zeros((len(review_ints), seq_len), dtype=int)\n",
    "\n",
    "for idx, row in enumerate(review_ints):\n",
    "    features[idx, -len(row):]=row[:seq_len]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_fract=0.8\n",
    "split_idx=int(len(features)*0.8)\n",
    "train_x, val_x=features[:split_idx], features[split_idx:]\n",
    "train_y, val_y=labels_int[:split_idx], labels_int[split_idx:]\n",
    "\n",
    "test_idx=int(len(val_x)*0.5)\n",
    "val_x, test_x=val_x[:test_idx], val_x[test_idx:]\n",
    "val_y, test_y=val_y[:test_idx], val_y[test_idx:]\n",
    "\n",
    "def get_batches(x, y, batch_size):\n",
    "    n_batches=len(x)//batch_size\n",
    "    x_, y_ = x[:n_batches*batch_size], y[:n_batches*batch_size]\n",
    "    for i in range(0, len(x), batch_size):\n",
    "        yield x_[i:i+batch_size], y_[i:i+batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_units=128\n",
    "lstm_layer=1\n",
    "batch_size=250\n",
    "embed_size=300\n",
    "n_words=len(vocab2int)+1 \n",
    "graph=tf.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    inputs=tf.placeholder(tf.int32, [None, None])\n",
    "    _labels=tf.placeholder(tf.int32, [None, None])\n",
    "    keep_prob=tf.placeholder(tf.float32)\n",
    "    \n",
    "    embed_weight=tf.Variable(tf.random_normal((n_words, embed_size), -1, 1))\n",
    "    embedding=tf.nn.embedding_lookup(embed_weight, inputs)\n",
    "    \n",
    "    def build_cell(n_units, keep_prob):\n",
    "        lstm=tf.contrib.rnn.BasicLSTMCell(n_units)\n",
    "        drop=tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob)\n",
    "        return drop\n",
    "     \n",
    "    cells=tf.contrib.rnn.MultiRNNCell([build_cell(n_units, keep_prob) for _ in range(lstm_layer)])\n",
    "    initial_state=cells.zero_state(batch_size, tf.float32)\n",
    "    \n",
    "    output, final_state=tf.nn.dynamic_rnn(cells, embedding, initial_state=initial_state)\n",
    "    \n",
    "    predictions=tf.contrib.layers.fully_connected(output[:, -1],1, activation_fn=tf.sigmoid)\n",
    "    cost=tf.losses.mean_squared_error(_labels, predictions)\n",
    "    optm=tf.train.AdamOptimizer(learning_rate=1e-3).minimize(cost)\n",
    "    \n",
    "    correct_pred=tf.equal(tf.cast(tf.round(predictions), tf.int32), _labels)\n",
    "    accuracy=tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "    saver=tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs=5\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    iteration=1\n",
    "    for e in range(epochs):\n",
    "        #batches=get_batches(train_x, train_y, batch_size)\n",
    "        state=sess.run(initial_state)\n",
    "        \n",
    "        for ii, (x, y) in enumerate(get_batches(train_x, train_y, batch_size), 1):\n",
    "        \n",
    "            feed={inputs:x,\n",
    "                 _labels:np.array(y)[:, None],\n",
    "                 keep_prob:0.75,\n",
    "                 initial_state:state}\n",
    "            \n",
    "            loss, state, _ = sess.run([cost, final_state, optm], feed_dict=feed)\n",
    "            \n",
    "            if iteration%5==0:\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {}\".format(iteration),\n",
    "                      \"Train loss: {:.3f}\".format(loss))\n",
    "                \n",
    "                \n",
    "            \n",
    "            if iteration%25==0:\n",
    "                val_acc=[]\n",
    "                valid_batches=get_batches(val_x, val_y, batch_size)\n",
    "                valid_state=sess.run(initial_state)\n",
    "                for x1, y1 in valid_batches:\n",
    "                    feed={inputs:x1,\n",
    "                         _labels:np.array(y1)[:, None],\n",
    "                         keep_prob:0.6,\n",
    "                         initial_state:valid_state}\n",
    "                    batch_acc, valid_state = sess.run([accuracy, final_state], feed_dict=feed)\n",
    "                    val_acc.append(batch_acc)\n",
    "                print(\"Val acc: {:.3f}\".format(np.mean(val_acc)))\n",
    "            \n",
    "            iteration+=1\n",
    "    \n",
    "    saver.save(sess, 'checkpoints/sentiments.ckpt')\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('custom test dataset', 'r') as custom:\n",
    "    file=custom.read()\n",
    "    \n",
    "def preprocess(file):\n",
    "    file=''.join([c for c in file if c not in punctuation])\n",
    "    split_reviews=file.split('\\n')\n",
    "    full_text=' '.join(split_reviews)\n",
    "    words=full_text.split()\n",
    "    review_ints=[]\n",
    "    for review in split_reviews:\n",
    "        review_ints.append([vocab2int[word] for word in review.split()])\n",
    "    \n",
    "    non_zero_idx=[i for i, r in enumerate(review_ints) if len(r)!=0]\n",
    "    review_ints=[review_ints[i] for i in non_zero_idx]\n",
    "    features=np.zeros((len(review_ints), seq_len), dtype=int)\n",
    "    \n",
    "    for idx, row in enumerate(review_ints):\n",
    "        features[idx, -len(row):]=row[:seq_len]\n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "user_test_reviews=preprocess(file)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 200)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/sentiments.ckpt\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nAssign requires shapes of both tensors to match. lhs shape= [384,512] rhs shape= [428,512]\n\t [[Node: save/Assign_16 = Assign[T=DT_FLOAT, _class=[\"loc:@rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Adam_1, save/RestoreV2/_33)]]\n\nCaused by op 'save/Assign_16', defined at:\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 497, in start\n    self.io_loop.start()\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/asyncio/base_events.py\", line 1434, in _run_once\n    handle._run()\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-31-00d3d1f2e385>\", line 25, in <module>\n    saver=tf.train.Saver()\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1281, in __init__\n    self.build()\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1293, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1330, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 778, in _build_internal\n    restore_sequentially, reshape)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 419, in _AddRestoreOps\n    assign_ops.append(saveable.restore(saveable_tensors, shapes))\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 112, in restore\n    self.op.get_shape().is_fully_defined())\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py\", line 216, in assign\n    validate_shape=validate_shape)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 60, in assign\n    use_locking=use_locking, name=name)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nAssign requires shapes of both tensors to match. lhs shape= [384,512] rhs shape= [428,512]\n\t [[Node: save/Assign_16 = Assign[T=DT_FLOAT, _class=[\"loc:@rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Adam_1, save/RestoreV2/_33)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Assign requires shapes of both tensors to match. lhs shape= [384,512] rhs shape= [428,512]\n\t [[Node: save/Assign_16 = Assign[T=DT_FLOAT, _class=[\"loc:@rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Adam_1, save/RestoreV2/_33)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1724\u001b[0m         sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1725\u001b[0;31m                  {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1726\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1290\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1291\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Assign requires shapes of both tensors to match. lhs shape= [384,512] rhs shape= [428,512]\n\t [[Node: save/Assign_16 = Assign[T=DT_FLOAT, _class=[\"loc:@rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Adam_1, save/RestoreV2/_33)]]\n\nCaused by op 'save/Assign_16', defined at:\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 497, in start\n    self.io_loop.start()\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/asyncio/base_events.py\", line 1434, in _run_once\n    handle._run()\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-31-00d3d1f2e385>\", line 25, in <module>\n    saver=tf.train.Saver()\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1281, in __init__\n    self.build()\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1293, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1330, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 778, in _build_internal\n    restore_sequentially, reshape)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 419, in _AddRestoreOps\n    assign_ops.append(saveable.restore(saveable_tensors, shapes))\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 112, in restore\n    self.op.get_shape().is_fully_defined())\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py\", line 216, in assign\n    validate_shape=validate_shape)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 60, in assign\n    use_locking=use_locking, name=name)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [384,512] rhs shape= [428,512]\n\t [[Node: save/Assign_16 = Assign[T=DT_FLOAT, _class=[\"loc:@rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Adam_1, save/RestoreV2/_33)]]\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-a76ce75992f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'checkpoints'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtest_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcells\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtest_batches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtest_acc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1757\u001b[0m       \u001b[0;31m# We add a more reasonable error message here to help users (b/110263146)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1758\u001b[0m       raise _wrap_restore_error_with_msg(\n\u001b[0;32m-> 1759\u001b[0;31m           err, \"a mismatch between the current graph and the graph\")\n\u001b[0m\u001b[1;32m   1760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m   def _restore_from_object_based_checkpoint(self, sess, save_path,\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nAssign requires shapes of both tensors to match. lhs shape= [384,512] rhs shape= [428,512]\n\t [[Node: save/Assign_16 = Assign[T=DT_FLOAT, _class=[\"loc:@rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Adam_1, save/RestoreV2/_33)]]\n\nCaused by op 'save/Assign_16', defined at:\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 497, in start\n    self.io_loop.start()\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/asyncio/base_events.py\", line 1434, in _run_once\n    handle._run()\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-31-00d3d1f2e385>\", line 25, in <module>\n    saver=tf.train.Saver()\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1281, in __init__\n    self.build()\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1293, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1330, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 778, in _build_internal\n    restore_sequentially, reshape)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 419, in _AddRestoreOps\n    assign_ops.append(saveable.restore(saveable_tensors, shapes))\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 112, in restore\n    self.op.get_shape().is_fully_defined())\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py\", line 216, in assign\n    validate_shape=validate_shape)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 60, in assign\n    use_locking=use_locking, name=name)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/home/prayag/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nAssign requires shapes of both tensors to match. lhs shape= [384,512] rhs shape= [428,512]\n\t [[Node: save/Assign_16 = Assign[T=DT_FLOAT, _class=[\"loc:@rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel/Adam_1, save/RestoreV2/_33)]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    test_state=sess.run(cells.zero_state(batch_size, tf.float32))\n",
    "    test_batches=get_batches(test_x, test_y, batch_size)\n",
    "    test_acc=[]\n",
    "    for x, y in test_batches:\n",
    "        feed={inputs:x,\n",
    "             _labels:np.array(y)[:, None],\n",
    "             keep_prob:1,\n",
    "             initial_state:test_state}\n",
    "        batch_acc, test_state = sess.run([accuracy, final_state], feed_dict=feed)\n",
    "        test_acc.append(batch_acc)\n",
    "        \n",
    "    print('test accuracy : {:.3f}'.format(np.mean(test_acc)))\n",
    "    \n",
    "    print(\"***************\\n\")\n",
    "    print(\"Checking model on user reviews...\\n\")\n",
    "    \n",
    "    predict=[]\n",
    "    #batch_size=4\n",
    "    state_=sess.run(initial_state)\n",
    "    values, state_=sess.run([predictions, final_state], feed_dict={inputs:user_test_reviews, initial_state:state_, keep_prob:1})\n",
    "    \n",
    "    for value in values:\n",
    "        predict.append([tf.cast(tf.round(value), tf.int32)])\n",
    "    \n",
    "    print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,  117,   18,\n",
       "         124,  108],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "         247,   30],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    3,   18,   17,   50,  729, 6014,  123,    5,    1,\n",
       "         432,  734],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "         627,   18]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.5841322  -1.8683769  -0.3828568  -0.8481432  -0.6080656 ]\n",
      " [-2.1439722   0.6790556  -2.8610876  -1.3981377  -1.4000592 ]\n",
      " [-1.1342047  -1.142002   -3.4780161   0.07325149 -1.1102241 ]\n",
      " [-0.58060104 -0.8401326  -1.4733518   0.26703286 -0.97050846]]\n",
      "\n",
      "\n",
      "[[[-2.1439722   0.6790556  -2.8610876  -1.3981377  -1.4000592 ]\n",
      "  [-1.1342047  -1.142002   -3.4780161   0.07325149 -1.1102241 ]\n",
      "  [ 0.          0.          0.          0.          0.        ]\n",
      "  [-0.58060104 -0.8401326  -1.4733518   0.26703286 -0.97050846]]\n",
      "\n",
      " [[-2.5841322  -1.8683769  -0.3828568  -0.8481432  -0.6080656 ]\n",
      "  [-1.1342047  -1.142002   -3.4780161   0.07325149 -1.1102241 ]\n",
      "  [-0.58060104 -0.8401326  -1.4733518   0.26703286 -0.97050846]\n",
      "  [-2.1439722   0.6790556  -2.8610876  -1.3981377  -1.4000592 ]]\n",
      "\n",
      " [[-0.58060104 -0.8401326  -1.4733518   0.26703286 -0.97050846]\n",
      "  [-1.1342047  -1.142002   -3.4780161   0.07325149 -1.1102241 ]\n",
      "  [-2.5841322  -1.8683769  -0.3828568  -0.8481432  -0.6080656 ]\n",
      "  [ 0.          0.          0.          0.          0.        ]]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "graph=tf.Graph()\n",
    "with graph.as_default():\n",
    "    weight=tf.Variable(tf.random_normal((4, 5), -1, 1))\n",
    "    inputs=tf.placeholder(tf.int32, [None, None])\n",
    "\n",
    "\n",
    "embed=tf.nn.embedding_lookup(weight, inputs)\n",
    "val=np.array([[1,2,4,3],[0,2,3,1],[3,2,0,4]])\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(weight))\n",
    "    print(\"\\n\")\n",
    "    print(sess.run(embed, feed_dict={inputs:val}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a=np.array([[1,2,3],[4,5,6],[7,8,9]])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
